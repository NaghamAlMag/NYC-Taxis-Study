{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting\n",
    "\n",
    "For the first point, We started downloading the yellow cab data for January 2018(yellow_tripdata_2018-01.csv). Our plan was to make our studies and analysis firstly for one month and then extend our results considering also other years.\n",
    "Our Data-set contains a really large amount of data so we opted to choose the simple pd.read_csv() module from pandas.\n",
    "After considering many options such as Dask DataFrames, we decided to use the pandas importing method together with the chucksize option. The solution to working with a massive file with eight milions of lines is to load the file in smaller chunks and analyze with the smaller chunks. Here is our code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tpep_pickup_datetime tpep_dropoff_datetime  trip_distance  PULocationID  \\\n",
      "0  2018-01-01 00:21:05   2018-01-01 00:24:23            0.5            41   \n",
      "1  2018-01-01 00:44:55   2018-01-01 01:03:05            2.7           239   \n",
      "2  2018-01-01 00:08:26   2018-01-01 00:14:21            0.8           262   \n",
      "3  2018-01-01 00:20:22   2018-01-01 00:52:51           10.2           140   \n",
      "4  2018-01-01 00:09:18   2018-01-01 00:27:06            2.5           246   \n",
      "\n",
      "   total_amount  \n",
      "0          5.80  \n",
      "1         15.30  \n",
      "2          8.30  \n",
      "3         34.80  \n",
      "4         16.55  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def data_aggregator(path,columnnumber,chunksize):\n",
    "    df_list = []\n",
    "    for chunk in pd.read_csv(path,usecols=columnnumber, chunksize=chunksize):\n",
    "        df_list.append(pd.DataFrame(chunk).dropna())\n",
    "    result = pd.concat(df_list)\n",
    "    del df_list\n",
    "    return result\n",
    "JanData=\"yellow_tripdata_2018-01.csv\" #We define the path of our data(of January)\n",
    "JanDF=data_aggregator(JanData,[1,2,4,7,16],10000)\n",
    "print(JanDF.head())\n",
    "#With this function we can easily import data we need. We select the columns and the dataset we desire and, as we said, \n",
    "#we use chunksize the make the function run faster(and to avoid memory problems). We have printed the head of the dataframe to\n",
    "#show that everything was correct and the df contained columns corresponding to [1,2,4,7,16] indexs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the function to import the data correctly, We were asked to merge our data with a .json file in the homework repo  ([.json](https://github.com/CriMenghini/ADM-2018/blob/master/Homework_2/taxi_zone_lookup.csv)). The data was embedd in the page source-code so we had to apply our knowledge in web-scraping ang get the lines of sourcecode we needed. We used the **Beautiful** package. We firstly collected all the location ids, then the boroughs, then the zones and finally the serving zones. We have done that noticing that in the sourcecode all the above information required where all starting with a <td> and we simply went trough all the values starting with it. After that we merged all together in a Pandas DataFrame called boroghFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"https://github.com/CriMenghini/ADM-2018/blob/master/Homework_2/taxi_zone_lookup.csv\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "ids=[]\n",
    "bor=[]\n",
    "zon=[]\n",
    "srv_zon=[]\n",
    "cell=0\n",
    "for i in range(2,1327,5):    #Firstly We get all the location ids\n",
    "    a=soup.find_all('td')[i].get_text()  \n",
    "    ids.append(a)\n",
    "    cell=cell+1\n",
    "    \n",
    "cell=0\n",
    "for i in range(3,1328,5):    #Then all the boroughs\n",
    "    a=soup.find_all('td')[i].get_text()\n",
    "    bor.append(a)\n",
    "    cell=cell+1\n",
    "    \n",
    "cell=0\n",
    "for i in range(4,1329,5):   #After that we get al zones\n",
    "    a=soup.find_all('td')[i].get_text()\n",
    "    zon.append(a)\n",
    "    cell=cell+1\n",
    "cell=0\n",
    "for i in range(5,1330,5):    #Finally we get all the seving zones\n",
    "    a=soup.find_all('td')[i].get_text()\n",
    "    srv_zon.append(a)\n",
    "    cell=cell+1\n",
    "# after getting all the informations needed we merged all the lists together\n",
    "data_tuples = list(zip(ids,bor,zon,srv_zon))\n",
    "boroughFrame=pd.DataFrame(data_tuples,columns = [\"PULocationID\", \"Borough\", \"Zone\", \"srv_zon\"]) #name columns assigned\n",
    "boroughFrame['PULocationID']=boroughFrame['PULocationID'].apply(int) #We wanted to be sure that PuLocationId were all ints.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we finally merged our Dataframes defining this function. We merged using the PULocation id column. **So we assumed that the LocationID in the .json file was equal to PULocationId in taxidataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8759874\n"
     ]
    }
   ],
   "source": [
    "def data_aggregator2(df1,df2,oncolumns,jointype):\n",
    "    result = pd.merge(df1, boroughFrame, on=oncolumns,how=jointype)\n",
    "    return result\n",
    "JanData=\"yellow_tripdata_2018-01.csv\" #We define the path of our data(of January)\n",
    "JanBoroughData=data_aggregator2(JanDF,boroughFrame,['PULocationID'],\"inner\")  \n",
    "print(len(JanBoroughData))\n",
    "del JanDF,boroughFrame,page,soup,ids,bor,zon,srv_zon \n",
    "#we also clean our memory deleting all the valuables we do not need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed, exploring our dataset, that we had some values simply not reasonable and we decided to get rid of them. For example, for some rows the trip distance was equal to 0 or negative and that values would have impacted our analysis. We removed the Nan values from the datasets because we tought that those would have affected our results. We lost approximately 55000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8704498\n"
     ]
    }
   ],
   "source": [
    "JanBoroughData = JanBoroughData[JanBoroughData.trip_distance >0]\n",
    "print(len(JanBoroughData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe a litte bit our datasets. Our original dataset had 16 columns and over 8 millions(yes, millions) rows. It has all the information related to taxi in 7 so called 'Boroughs'. We decided to exclude from our analysis the 'EWR' and 'Unknown' boroughs because they had what appeared to be fictional values. For example, in EWR you can find a total price for the trip of 600$ for a 200 meters path. We have extended these hypothesis also to other monthsd\n",
    "Anyway,  We decided to import just the columns corresping to those indexes:**[1,2,4,7,16]**\n",
    "\n",
    "As we said we have only 5 Boroughs: Manhattan, Bronx, Brooklyn, Staten Island and Queens. The Borough with the maximum numbers of observation is undoubtly Manhattan, center of the economical life of New York. Bronx and Staten Island both have a really low number of observations.\n",
    "\n",
    "We have two columns, which will be used to calculate the time of the trip,  in a datetime format. They show date and time of pickup and dropoff. \n",
    "\n",
    "The maximum amount money spent for a single taxi trip has been spent in Queens and corresponds to 3006 dollars fro a trip distance of 189483.84 miles. On average, Queens is the most expensive borough as well with a mean of 11.6 miles per trip. We will see that these result won't be confirmed in we consider \n",
    "$$ \\frac{totalamount}{tripdistance}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>Zone</th>\n",
       "      <th>srv_zon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borogh</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bronx</th>\n",
       "      <td>2018-01-31 23:56:14</td>\n",
       "      <td>2018-02-01 00:15:04</td>\n",
       "      <td>110.29</td>\n",
       "      <td>259</td>\n",
       "      <td>371.17</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brooklyn</th>\n",
       "      <td>2018-01-31 23:59:32</td>\n",
       "      <td>2018-02-01 22:08:33</td>\n",
       "      <td>123.30</td>\n",
       "      <td>257</td>\n",
       "      <td>510.30</td>\n",
       "      <td>Windsor Terrace</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EWR</th>\n",
       "      <td>2018-01-31 18:31:28</td>\n",
       "      <td>2018-01-31 18:31:55</td>\n",
       "      <td>48.20</td>\n",
       "      <td>1</td>\n",
       "      <td>195.30</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manhattan</th>\n",
       "      <td>2018-07-27 04:06:37</td>\n",
       "      <td>2018-07-27 04:46:57</td>\n",
       "      <td>830.80</td>\n",
       "      <td>263</td>\n",
       "      <td>1017.30</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queens</th>\n",
       "      <td>2018-02-01 23:51:33</td>\n",
       "      <td>2018-02-02 00:21:03</td>\n",
       "      <td>189483.84</td>\n",
       "      <td>260</td>\n",
       "      <td>3006.80</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staten Island</th>\n",
       "      <td>2018-01-30 21:18:37</td>\n",
       "      <td>2018-01-30 21:32:04</td>\n",
       "      <td>28.11</td>\n",
       "      <td>251</td>\n",
       "      <td>176.32</td>\n",
       "      <td>Westerleigh</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>2018-01-31 23:59:25</td>\n",
       "      <td>2018-02-01 17:59:31</td>\n",
       "      <td>128.73</td>\n",
       "      <td>265</td>\n",
       "      <td>8016.80</td>\n",
       "      <td>NV</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tpep_pickup_datetime tpep_dropoff_datetime  trip_distance  \\\n",
       "Borogh                                                                    \n",
       "Bronx          2018-01-31 23:56:14   2018-02-01 00:15:04         110.29   \n",
       "Brooklyn       2018-01-31 23:59:32   2018-02-01 22:08:33         123.30   \n",
       "EWR            2018-01-31 18:31:28   2018-01-31 18:31:55          48.20   \n",
       "Manhattan      2018-07-27 04:06:37   2018-07-27 04:46:57         830.80   \n",
       "Queens         2018-02-01 23:51:33   2018-02-02 00:21:03      189483.84   \n",
       "Staten Island  2018-01-30 21:18:37   2018-01-30 21:32:04          28.11   \n",
       "Unknown        2018-01-31 23:59:25   2018-02-01 17:59:31         128.73   \n",
       "\n",
       "               PULocationID  total_amount                Zone      srv_zon  \n",
       "Borogh                                                                      \n",
       "Bronx                   259        371.17  Woodlawn/Wakefield    Boro Zone  \n",
       "Brooklyn                257        510.30     Windsor Terrace    Boro Zone  \n",
       "EWR                       1        195.30      Newark Airport          EWR  \n",
       "Manhattan               263       1017.30      Yorkville West  Yellow Zone  \n",
       "Queens                  260       3006.80            Woodside    Boro Zone  \n",
       "Staten Island           251        176.32         Westerleigh    Boro Zone  \n",
       "Unknown                 265       8016.80                  NV          N/A  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JanBoroughData.groupby(['Borogh']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Borogh</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bronx</th>\n",
       "      <td>3.622784</td>\n",
       "      <td>172.443562</td>\n",
       "      <td>16.865593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brooklyn</th>\n",
       "      <td>3.328930</td>\n",
       "      <td>107.116736</td>\n",
       "      <td>16.413084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EWR</th>\n",
       "      <td>6.965495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.133352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manhattan</th>\n",
       "      <td>2.241565</td>\n",
       "      <td>165.055234</td>\n",
       "      <td>13.520815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queens</th>\n",
       "      <td>11.685727</td>\n",
       "      <td>136.523287</td>\n",
       "      <td>44.330302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staten Island</th>\n",
       "      <td>4.621171</td>\n",
       "      <td>81.990991</td>\n",
       "      <td>27.932072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>2.705425</td>\n",
       "      <td>264.011207</td>\n",
       "      <td>15.868795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               trip_distance  PULocationID  total_amount\n",
       "Borogh                                                  \n",
       "Bronx               3.622784    172.443562     16.865593\n",
       "Brooklyn            3.328930    107.116736     16.413084\n",
       "EWR                 6.965495      1.000000     81.133352\n",
       "Manhattan           2.241565    165.055234     13.520815\n",
       "Queens             11.685727    136.523287     44.330302\n",
       "Staten Island       4.621171     81.990991     27.932072\n",
       "Unknown             2.705425    264.011207     15.868795"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JanBoroughData.groupby(['Borogh']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
